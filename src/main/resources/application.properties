spring.application.name=langchain4j-demo
spring.threads.virtual.enabled=true

# Startup performance optimizations
spring.main.lazy-initialization=true
spring.main.register-shutdown-hook=false
spring.jmx.enabled=false

# Web optimizations
spring.mvc.log-request-details=false
spring.web.resources.cache.cachecontrol.max-age=365d
spring.mustache.check-template-location=false

# Logging optimizations
logging.level.dev.langchain4j=INFO
logging.level.com.azure=WARN
logging.level.org.springframework=WARN
logging.level.org.springframework.web=WARN
logging.pattern.console=%d{HH:mm:ss.SSS} %clr(%-5p) [%-10.10t] - %-13.13c : %m%n

#########" Configure the vector store and the LLMs to use #########
# Option 1: if you use Azure
#  __Chat Model__: Microsoft Foundry with gpt-5-mini
#  __Image Model__: Microsoft Foundry with dalle-3
#  __Embedding model__: Microsoft Foundry with text-embedding-ada
# __Embedding store__: Azure AI Search
#########
#
spring.profiles.active=azure

#########
# Option 2: Fully local
# __Chat Model__: Ollama with llama3.2:1b (see [https://ollama.com/library/llama3.2](https://ollama.com/library/llama3.2))
# __Image Model__: Not available
# __Embedding model__: Ollama with nomic-embed-text (see [https://ollama.com/library/nomic-embed-text](https://ollama.com/library/nomic-embed-text))
# __Embedding store__: Elasticsearch
#########
#spring.profiles.active=local

