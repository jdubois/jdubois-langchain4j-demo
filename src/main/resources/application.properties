spring.application.name=langchain4j-demo
spring.threads.virtual.enabled=true
logging.level.dev.langchain4j=DEBUG

#########" Configure the vector store and the LLMs to use #########
# Option 1: if you use Azure
# Chat Model: Azure OpenAI with gpt-4o
# Embedding model: Azure OpenAI with text-embedding-ada
# Embedding store: Azure AI Search
#########
#
#spring.profiles.active=azure
#
#########
# Option 2: the smallest -> fully local, not very good, but small and fast
# Chat Model: Ollama with tinyllama
# Embedding model: in-memory Java with AllMiniLmL6V2EmbeddingModel
# Embedding store: Qdrant
#########
#
spring.profiles.active=small
#
#########
# Option 3: good & local
# Chat Model: Ollama with Phi 3.5
# Embedding model: Ollama with nomic-embed-text
# Embedding store: Qdrant
#########
#spring.profiles.active=good
#
#########
# Option 4: using GitHub Models
# Chat Model: GitHub Models with gpt-4o-mini
# Embedding model: GitHub Models with text-embedding-3-small
# Embedding store: Qdrant
#########
#
#spring.profiles.active=github
#
#########
# Option 5: using Elasticsearch as an embedding store
# Chat Model: Ollama with Phi 3.5
# Embedding model: Ollama with nomic-embed-text
# Embedding store: Elasticsearch
#########
#
#spring.profiles.active=elasticsearch
#
